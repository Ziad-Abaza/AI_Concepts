import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer

###############################################################
# تحميل البيانات من ملف CSV واختيار الأعمدة
################################################################
df = pd.read_csv('assets/spam.csv', encoding='latin-1')

# تحديد الأعمدة
df = df[['v1', 'v2']]
# v1: يمثل التصنيف (إما "spam" أو "ham").
# v2: يمثل الرسالة النصية التي ترغب في تحليلها.

# إعادة تسمية الأعمدة
df.columns = ['Category', 'Message']

###############################################################
# تصفية الرسائل إلى فئتي spam و ham وعرض عددها
################################################################
spam = df[df['Category'] == 'spam']
ham = df[df['Category'] == 'ham']

# عرض عدد رسائل spam و ham
print(f"spam: {len(spam)}")
print(f"ham: {len(ham)}")
print('----------------------------------------------------------------------')

###############################################################
# تحويل الفئات النصية إلى قيم عددية (1 و 0) لتسهيل التحليل
################################################################
# "ham" سيتم تحويله إلى 1 (يمثل البريد العادي).
# "spam" سيتم تحويله إلى 0 (يمثل البريد العشوائي).
df.loc[df['Category'] == 'ham', 'Category'] = 1
df.loc[df['Category'] == 'spam', 'Category'] = 0

# التأكد من نوع البيانات
df['Category'] = df['Category'].astype(int)

# عرض أول 5 أسطر للتأكد من التعديلات
print(df.head())
print('----------------------------------------------------------------------')

###############################################################
# فصل البيانات إلى الرسائل والتصنيفات
################################################################
category = df['Category']
message = df['Message']

###############################################################
# تحويل الرسائل إلى تمثيل TF-IDF
################################################################
# min_df: الحد الأدنى للتكرار (تضمين المصطلحات التي تظهر في أي مستند).
# stop_words: كلمات شائعة يتم استبعادها من التحليل.
tf_idf = TfidfVectorizer(min_df=1, stop_words='english')

# تحويل النصوص إلى تمثيلات عددية
X = tf_idf.fit_transform(message)

###############################################################
# تقسيم البيانات إلى مجموعتي تدريب واختبار
################################################################
# X_train: مصفوفة مميزات التدريب.
# X_test: مصفوفة مميزات الاختبار.
# y_train: التصنيفات المستهدفة للتدريب.
# y_test: التصنيفات المستهدفة للاختبار.
X_train, X_test, y_train, y_test = train_test_split(X, category, test_size=0.2, random_state=42)

###############################################################
# استخدام نموذج Multinomial Naive Bayes لتصنيف النصوص
################################################################
model = MultinomialNB()

# تدريب النموذج
model.fit(X_train, y_train)

###############################################################
# اختبار النموذج على مجموعة الاختبار وحساب الدقة
################################################################
y_pred = model.predict(X_test)

# حساب دقة النموذج
accuracy = np.mean(y_pred == y_test)
print(f"Accuracy: {accuracy * 100:.2f}%")

###############################################################
# عرض بعض التوقعات لمقارنتها بالنتائج الفعلية
################################################################
print('----------------------------------------------------------------------')
print("Predicted:", y_pred[:10])
print("Actual:   ", y_test[:10].values)
